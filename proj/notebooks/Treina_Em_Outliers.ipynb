{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2977ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "PUBTAB_ANN = '../../pubtabnet/anns/train/'\n",
    "PUBTAB_IMG = '../../pubtabnet/imgs/train/'\n",
    "\n",
    "ANN_PATH = PUBTAB_ANN\n",
    "IMAGE_PATH = PUBTAB_IMG\n",
    "IMG_FORMAT = '.png'\n",
    "\n",
    "with open(ANN_PATH[:-1] + '_outlier_trunc_filelist.json') as file:\n",
    "    unallowed_list = file.read().splitlines()\n",
    "with open(ANN_PATH[:-1] + '_trunc_filelist.json') as file:\n",
    "    allowed_list = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e6667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = []\n",
    "\n",
    "for json_item in allowed_list:\n",
    "    aux_list.append(json_item[:-5])\n",
    "\n",
    "allowed_list = aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8a3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = []\n",
    "\n",
    "for json_item in unallowed_list:\n",
    "    aux_list.append(json_item[:-5])\n",
    "\n",
    "unallowed_list = aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c72267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMC4357343_004_00',\n",
       " 'PMC2873801_006_00',\n",
       " 'PMC5790457_005_00',\n",
       " 'PMC4882839_006_00',\n",
       " 'PMC4425873_002_00',\n",
       " 'PMC5707723_004_00',\n",
       " 'PMC4335538_003_00',\n",
       " 'PMC3797567_004_00',\n",
       " 'PMC2944093_004_00',\n",
       " 'PMC3987684_005_00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unallowed_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004bf972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMC6051241_006_00',\n",
       " 'PMC3398398_014_00',\n",
       " 'PMC2682793_006_00',\n",
       " 'PMC6082926_006_00',\n",
       " 'PMC2809502_009_00',\n",
       " 'PMC3890642_004_00',\n",
       " 'PMC3926592_006_01',\n",
       " 'PMC548940_003_00',\n",
       " 'PMC4394591_006_00',\n",
       " 'PMC1906827_006_00']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ae6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 19:51:00.073266: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-28 19:51:00.073290: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-28 19:51:00.073307: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-28 19:51:00.716499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers import VisionEncoderDecoderConfig\n",
    "import torch\n",
    "\n",
    "image_size = [750, 750]\n",
    "max_length = 4096#config.decoder.max_position_embeddings\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"../../pubtabnet/modelos/Donut_PubTables_TML_Processor\")\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb523f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = [\"<cell>\", \"<row_and_col_header>\", \"<row_header>\", \"<col_header>\"]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            cell_types.append(\"<span_type=0\" + str(i) + str(j) + str(k) + \">\")\n",
    "            cell_types.append(\"<span_type=1\" + str(i) + str(j) + str(k) + \">\")\n",
    "\n",
    "\n",
    "cell_tokens = [processor.tokenizer.convert_tokens_to_ids([cell_type])[0] for cell_type in cell_types]\n",
    "row_tokens = [processor.tokenizer.convert_tokens_to_ids([row_type])[0] for row_type in ['<row>', '</s>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a531882",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = config.decoder\n",
    "\n",
    "new_config.pos_counters = [cell_tokens, row_tokens]\n",
    "new_config.dim_max_position_embeddings = [5000, 300, 300]\n",
    "new_config.architectures = \"DiMBartForCausalLM\"\n",
    "new_config.model_type = \"dimbart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4437fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DiMBartConfig\n",
    "\n",
    "new_config = DiMBartConfig(**new_config.__dict__)\n",
    "new_config.pos_counters = new_config.pos_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8320a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.decoder = new_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1935ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderConfig {\n",
       "  \"_name_or_path\": \"naver-clova-ix/donut-base\",\n",
       "  \"architectures\": [\n",
       "    \"VisionEncoderDecoderModel\"\n",
       "  ],\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"add_final_layer_norm\": true,\n",
       "    \"architectures\": \"DiMBartForCausalLM\",\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 4,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"dim_max_position_embeddings\": [\n",
       "      5000,\n",
       "      300,\n",
       "      300\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 1536,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"dimbart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"offset\": 2,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"pos_counters\": [\n",
       "      [\n",
       "        57528,\n",
       "        57529,\n",
       "        57530,\n",
       "        57531,\n",
       "        57543,\n",
       "        57544,\n",
       "        57545,\n",
       "        57546,\n",
       "        57547,\n",
       "        57548,\n",
       "        57549,\n",
       "        57550,\n",
       "        57551,\n",
       "        57552,\n",
       "        57553,\n",
       "        57554,\n",
       "        57555,\n",
       "        57556,\n",
       "        57557,\n",
       "        57558\n",
       "      ],\n",
       "      [\n",
       "        57527,\n",
       "        2\n",
       "      ]\n",
       "    ],\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": true,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 57525\n",
       "  },\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": null,\n",
       "    \"attention_probs_dropout_prob\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      14,\n",
       "      2\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"drop_path_rate\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"embed_dim\": 128,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.0,\n",
       "    \"hidden_size\": 1024,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"image_size\": [\n",
       "      2560,\n",
       "      1920\n",
       "    ],\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-05,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"min_length\": 0,\n",
       "    \"mlp_ratio\": 4.0,\n",
       "    \"model_type\": \"donut-swin\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_channels\": 3,\n",
       "    \"num_heads\": [\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32\n",
       "    ],\n",
       "    \"num_layers\": 4,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"patch_size\": 4,\n",
       "    \"path_norm\": true,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"qkv_bias\": true,\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_absolute_embeddings\": false,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"window_size\": 10\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"vision-encoder-decoder\",\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.35.0.dev0\"\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ed9782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at naver-clova-ix/donut-base were not used when initializing VisionEncoderDecoderModel: ['decoder.model.decoder.embed_positions.weight', 'decoder.model.decoder.layer_norm.weight', 'decoder.model.decoder.layer_norm.bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at naver-clova-ix/donut-base and are newly initialized: ['decoder.model.decoder.embed_positions.embeddings.0.weight', 'decoder.model.decoder.embed_positions.embeddings.2.weight', 'decoder.model.decoder.embed_positions.embeddings.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config = config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b02792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('aux_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74cf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"msg.json\", 'w') as out:\n",
    "        json.dump({'outputs': []}, out, ensure_ascii=False, indent=4)\n",
    "\n",
    "def write_msg(msg):\n",
    "    with open(\"msg.json\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    with open(\"msg.json\", 'w') as out:\n",
    "        json_data['outputs'].append(msg)\n",
    "        json.dump(json_data, out, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bba3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cel2token(cell):\n",
    "    if cell['span_type'][10:] != '0000':\n",
    "        sequence = \"<\" + cell['span_type'] + \">\"\n",
    "    else:\n",
    "        sequence = \"\"\n",
    "    \n",
    "    if cell['span_type'][10:] in ['0000', '0100', '1000', '1100']:\n",
    "        if cell['row_header'] and cell['col_header']:\n",
    "            sequence += \"<row_and_col_header>\"\n",
    "        elif cell['col_header']:\n",
    "            sequence += \"<col_header>\"\n",
    "        elif cell['row_header']:\n",
    "            sequence += \"<row_header>\"\n",
    "        else:\n",
    "            sequence += \"<cell>\"\n",
    "        sequence += cell['content']\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def row2token(row):\n",
    "    sequence = \"<row>\"\n",
    "    for cell in row:\n",
    "        sequence += cel2token(cell)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "\n",
    "def table2token(table):\n",
    "    sequence = \"<table>\"\n",
    "    for row in table:\n",
    "        sequence += row2token(row)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "\n",
    "def json2token(json):\n",
    "    sequence = \"\"\n",
    "    if('tables' in json):\n",
    "        for table in json['tables']:\n",
    "            sequence += table2token(table)\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d32c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonutTableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        image_size,\n",
    "        max_length,\n",
    "        shuffle = True,\n",
    "        split = \"train\",\n",
    "        ignore_id = -100,\n",
    "        prompt_end_token = None,\n",
    "    ):            \n",
    "        self.annotations = annotations\n",
    "        \n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        \n",
    "        self.resize = transforms.Compose([transforms.Resize(image_size)])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.annotations[idx]\n",
    "        \n",
    "        with open(ANN_PATH + file_name + \".json\", encoding=\"utf-8\") as f:\n",
    "            annotation = json.load(f)\n",
    "        \n",
    "        image = Image.open(IMAGE_PATH + file_name + IMG_FORMAT)\n",
    "        \n",
    "        \n",
    "        # inputs\n",
    "        pixel_values = processor(image.convert(\"RGB\"), random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "        \n",
    "        target_sequence = json2token(annotation)\n",
    "        \n",
    "        input_ids = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=True,\n",
    "            max_length= max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id\n",
    "        \n",
    "        \n",
    "        encoding = dict(pixel_values=pixel_values,\n",
    "                        labels=labels)\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids([\"<table_extraction>\"])[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29be2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "avg_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb981e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import choices\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 10):\n",
    "    allowed_smpl = choices(allowed_list, k = len(unallowed_list))\n",
    "    train_dataset = DonutTableDataset(unallowed_list + allowed_smpl, max_length = max_length, image_size = image_size)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    \n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    mean_loss = 0\n",
    "    mean_smpl_loss = 0 \n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mean_loss += loss.item()   \n",
    "        mean_smpl_loss += loss.item() \n",
    "        if i % avg_size == 0:\n",
    "            print(\"Loss: \", mean_smpl_loss/avg_size)\n",
    "            write_msg(\"batch \" + str(i) +\" loss: \"+ str(mean_smpl_loss/avg_size))\n",
    "            mean_smpl_loss = 0 \n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            model.save_pretrained(\"model_epoch_checkpoint\")\n",
    "    \n",
    "    torch.save(model, \"model_epoch_checkpoint_.bin\")\n",
    "    print(\"Epoch's mean loss: \", mean_loss/len(train_dataloader))\n",
    "    \n",
    "    write_msg(\"Epoch checkpointed: \" + str(epoch+1) +\" \\n\"+\n",
    "              \"Epoch's mean Loss: \" + str(mean_loss/len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../../pubtabnet/model-minimal-long-epoch10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dfb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(\"../../pubtabnet/Donut_PubTables_Processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6cd87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a8b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
