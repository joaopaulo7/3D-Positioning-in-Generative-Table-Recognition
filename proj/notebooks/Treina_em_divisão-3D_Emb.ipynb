{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2977ba19",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../aux/data/anns/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m MODELS_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../aux/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m IMG_FORMAT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m json_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mANN_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../aux/data/anns/train/'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from transformers import DonutProcessor\n",
    "from modeling_tabeleiro import TabeleiroModel\n",
    "from processing_tabeleiro import TabeleiroProcessor\n",
    "\n",
    "ANN_PATH = '../../aux/data/anns/train/'\n",
    "IMAGE_PATH = '../../aux/data/imgs/train/'\n",
    "\n",
    "PROCESSORS_PATH = \"../../aux/processors/\"\n",
    "MODELS_PATH = \"../../aux/models/\"\n",
    "\n",
    "IMG_FORMAT = '.png'\n",
    "\n",
    "json_list = os.listdir(ANN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef480573",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = []\n",
    "\n",
    "for json_item in json_list:\n",
    "    if json_item[-6] != \"L\":\n",
    "        aux_list.append(json_item[:-5])\n",
    "\n",
    "json_list = aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c72267",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = json_list\n",
    "json_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ae6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers import VisionEncoderDecoderConfig\n",
    "import torch\n",
    "\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(MODELS_PATH+\"donut-base\")\n",
    "\n",
    "image_size = [640, 640]\n",
    "max_length = 960\n",
    "\n",
    "\n",
    "config.encoder.image_size = image_size\n",
    "processor = TabeleiroProcessor.from_pretrained(PROCESSORS_PATH+'donut-base')#\"Donut_PubTables_TML_Processor8k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe271bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = [\"<table_extraction>\", \"<table>\", \"<row>\", \"<cell>\", \"<row_and_col_header>\", \"<row_header>\", \"<col_header>\"]\n",
    "new_tokens += [\"<content_row_and_col_header>\", \"<content_row_header>\", \"<content_col_header>\", \"<content>\"]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            new_tokens.append(\"<span_type=0\" + str(i) + str(j) + str(k) + \">\")\n",
    "            new_tokens.append(\"<span_type=1\" + str(i) + str(j) + str(k) + \">\")\n",
    "\n",
    "\n",
    "processor.tokenizer.add_tokens(new_tokens, special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50455328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = [\"<cell>\", \"<row_and_col_header>\", \"<row_header>\", \"<col_header>\"]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            cell_types.append(\"<span_type=0\" + str(i) + str(j) + str(k) + \">\")\n",
    "            cell_types.append(\"<span_type=1\" + str(i) + str(j) + str(k) + \">\")\n",
    "\n",
    "\n",
    "cell_tokens = [processor.tokenizer.convert_tokens_to_ids([cell_type])[0] for cell_type in cell_types]\n",
    "row_tokens = [processor.tokenizer.convert_tokens_to_ids([row_type])[0] for row_type in ['<row>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7649821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<row>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(row_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38575e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the decoder: <class 'modeling_dimbart.DiMBartForCausalLM'> is overwritten by shared decoder config: DiMBartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"dim_max_position_embeddings\": [\n",
      "    512,\n",
      "    120,\n",
      "    120\n",
      "  ],\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"max_position_embeddings\": 1536,\n",
      "  \"model_type\": \"dimbart\",\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pos_counters\": [\n",
      "    [\n",
      "      57532,\n",
      "      57535,\n",
      "      57534,\n",
      "      57533,\n",
      "      57536,\n",
      "      57537,\n",
      "      57538,\n",
      "      57539,\n",
      "      57540,\n",
      "      57541,\n",
      "      57542,\n",
      "      57543,\n",
      "      57544,\n",
      "      57545,\n",
      "      57546,\n",
      "      57547,\n",
      "      57548,\n",
      "      57549,\n",
      "      57550,\n",
      "      57551\n",
      "    ],\n",
      "    [\n",
      "      57527\n",
      "    ]\n",
      "  ],\n",
      "  \"scale_embedding\": true,\n",
      "  \"transformers_version\": \"4.41.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 57525\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(57552, 1024)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.torch_dtype='bfloat16'\n",
    "\n",
    "model = TabeleiroModel.from_pretrained(\"naver-clova-ix/donut-base\",\n",
    "                                       from_donut=True,\n",
    "                                       decoder_extra_config={\"pos_counters\":[cell_tokens, row_tokens]},\n",
    "                                       donut_config = config,\n",
    "                                       ignore_mismatched_sizes=True)\n",
    "model.decoder.resize_token_embeddings(len(processor.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc6e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderConfig {\n",
       "  \"_name_or_path\": \"naver-clova-ix/donut-base\",\n",
       "  \"architectures\": [\n",
       "    \"VisionEncoderDecoderModel\"\n",
       "  ],\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"add_final_layer_norm\": true,\n",
       "    \"architectures\": null,\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 4,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"dim_max_position_embeddings\": [\n",
       "      512,\n",
       "      120,\n",
       "      120\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 1536,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"dimbart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"pos_counters\": [\n",
       "      [\n",
       "        57532,\n",
       "        57535,\n",
       "        57534,\n",
       "        57533,\n",
       "        57536,\n",
       "        57537,\n",
       "        57538,\n",
       "        57539,\n",
       "        57540,\n",
       "        57541,\n",
       "        57542,\n",
       "        57543,\n",
       "        57544,\n",
       "        57545,\n",
       "        57546,\n",
       "        57547,\n",
       "        57548,\n",
       "        57549,\n",
       "        57550,\n",
       "        57551\n",
       "      ],\n",
       "      [\n",
       "        57527\n",
       "      ]\n",
       "    ],\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": true,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 57552\n",
       "  },\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": null,\n",
       "    \"attention_probs_dropout_prob\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      14,\n",
       "      2\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"drop_path_rate\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"embed_dim\": 128,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.0,\n",
       "    \"hidden_size\": 1024,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"image_size\": [\n",
       "      640,\n",
       "      640\n",
       "    ],\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-05,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"min_length\": 0,\n",
       "    \"mlp_ratio\": 4.0,\n",
       "    \"model_type\": \"donut-swin\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_channels\": 3,\n",
       "    \"num_heads\": [\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32\n",
       "    ],\n",
       "    \"num_layers\": 4,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"patch_size\": 4,\n",
       "    \"path_norm\": true,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"qkv_bias\": true,\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_absolute_embeddings\": false,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"window_size\": 10\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"vision-encoder-decoder\",\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.41.0\"\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63430609",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.image_processor.size = image_size[::-1] # should be (width, height)\n",
    "#processor.image_processor.size = {'width': image_size[::-1][0], 'height': image_size[::-1][1]}\n",
    "processor.image_processor.do_align_long_axis = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c74cf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"msg.json\", 'w') as out:\n",
    "        json.dump({'outputs': []}, out, ensure_ascii=False, indent=4)\n",
    "\n",
    "def write_msg(msg):\n",
    "    with open(\"msg.json\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    with open(\"msg.json\", 'w') as out:\n",
    "        json_data['outputs'].append(msg)\n",
    "        json.dump(json_data, out, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d32c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonutTableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        image_size,\n",
    "        max_length,\n",
    "        shuffle = True,\n",
    "        split = \"train\",\n",
    "        ignore_id = -100,\n",
    "        prompt_end_token = None,\n",
    "    ):            \n",
    "        self.annotations = annotations\n",
    "        \n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.annotations[idx]\n",
    "        \n",
    "        with open(ANN_PATH + file_name + \".json\", encoding=\"utf-8\") as f:\n",
    "            annotation = json.load(f)\n",
    "        \n",
    "        image = Image.open(IMAGE_PATH + file_name + IMG_FORMAT)\n",
    "        \n",
    "        \n",
    "        # inputs\n",
    "        pixel_values = processor(image.convert(\"RGB\"), random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        pixel_values = pixel_values.squeeze().to(torch.bfloat16)\n",
    "        \n",
    "        target_sequence = processor.json2token(annotation)+\"</s>\"\n",
    "        \n",
    "        input_ids = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length= max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id\n",
    "        \n",
    "        \n",
    "        encoding = dict(pixel_values=pixel_values,\n",
    "                        labels=labels,\n",
    "                        target = target_sequence,\n",
    "                       filename = file_name)\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5c2595e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m DonutTableDataset(\u001b[43mjson_list\u001b[49m,\n\u001b[1;32m      2\u001b[0m                              max_length \u001b[38;5;241m=\u001b[39m max_length,\n\u001b[1;32m      3\u001b[0m                              image_size \u001b[38;5;241m=\u001b[39m image_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_list' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = DonutTableDataset(json_list,\n",
    "                             max_length = max_length,\n",
    "                             image_size = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c6d668",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, num_workers=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29be2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointed = False\n",
    "if checkpointed:\n",
    "    model = TabeleiroModel.from_pretrained(\"../../pubtabnet/checkpoints/TML-5lre-5-checkpoint\")\n",
    "\n",
    "start_epoch = 0\n",
    "avg_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d7f93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids([\"<table_extraction>\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cb981e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8e-5\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m27\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m), gamma\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.125\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m27\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpointed:\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../pubtabnet/checkpoints/optim-checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model.to(device) \n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=8e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=len(train_dataloader)//(27*4), gamma=(0.125)**(1/27))\n",
    "\n",
    "if checkpointed:\n",
    "    optimizer.load_state_dict(torch.load(\"../../pubtabnet/checkpoints/optim-checkpoint\"))\n",
    "\n",
    "num_steps = 0   \n",
    "\n",
    "for epoch in range(start_epoch, 2):\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    mean_loss = 0\n",
    "    mean_smpl_loss = 0 \n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "            \n",
    "        batch = {k: v.to(device) if k not in [\"target\", \"filename\"] else v for k, v in batch.items()}\n",
    "        \n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        \n",
    "        \n",
    "        loss = outputs.loss\n",
    "        mean_loss += loss.item()   \n",
    "        mean_smpl_loss += loss.item()\n",
    "        \n",
    "        loss /= 4\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i+1)%4 == 0 or i+1 == len(train_dataloader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            num_steps += 1\n",
    "            if num_steps%10000 == 0 :\n",
    "                model.save_pretrained(\"../../aux/modelos/by_step/model-3D-STEP_\"+str(num_steps))\n",
    "            \n",
    "            if  scheduler.get_last_lr()[0] > 7.5e-6:\n",
    "                scheduler.step() \n",
    "                \n",
    "        if i % avg_size == 0:\n",
    "            print(str(i) + \" Loss: \", mean_smpl_loss/avg_size)\n",
    "            write_msg(\"batch \" + str(i) +\" loss: \"+ str(mean_smpl_loss/avg_size))\n",
    "            mean_smpl_loss = 0 \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    model.save_pretrained(\"../../aux/modelos/checkpoints/TML-5lre-5-8kproc-checkpoint-epoch\"+str(epoch))\n",
    "    print(\"Epoch's mean loss: \", mean_loss/len(train_dataloader))\n",
    "    \n",
    "    write_msg(\"Epoch checkpointed: \" + str(epoch+1) +\" \\n\"+\n",
    "              \"Epoch's mean Loss: \" + str(mean_loss/len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.decode([57525, 57526, 57527])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../../aux/modelos/model-3D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041efb6d",
   "metadata": {},
   "source": [
    "#### processor.save_pretrained(\"../../pubtabnet/processors/processor-GTML-8kproc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6cd87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2375e00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
