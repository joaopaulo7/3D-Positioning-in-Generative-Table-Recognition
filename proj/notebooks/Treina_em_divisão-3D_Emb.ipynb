{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2977ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from transformers import DonutProcessor\n",
    "from modeling_tabeleiro import TabeleiroModel\n",
    "\n",
    "ANN_PATH = '../../aux/data/anns/train/'\n",
    "IMAGE_PATH = '../../aux/data/imgs/train/'\n",
    "\n",
    "PROCESSORS_PATH = \"../../aux/processors/\"\n",
    "MODELS_PATH = \"../../aux/models/\"\n",
    "\n",
    "IMG_FORMAT = '.png'\n",
    "\n",
    "json_list = os.listdir(ANN_PATH)\n",
    "    \n",
    "json_list = [item for item in json_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef480573",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = []\n",
    "\n",
    "for json_item in json_list:\n",
    "    if json_item[-6] != \"L\":\n",
    "        aux_list.append(json_item[:-5])\n",
    "\n",
    "json_list = aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c72267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMC3549936_002_00',\n",
       " 'PMC3112512_009_00',\n",
       " 'PMC3772909_007_00',\n",
       " 'PMC5294720_004_00',\n",
       " 'PMC3446317_008_00',\n",
       " 'PMC5071235_005_00',\n",
       " 'PMC1421390_001_00',\n",
       " 'PMC5251219_004_01',\n",
       " 'PMC3973966_003_00',\n",
       " 'PMC4147206_002_00']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_list = json_list\n",
    "json_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6ae6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers import VisionEncoderDecoderConfig\n",
    "import torch\n",
    "\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(MODELS_PATH+\"donut-base\")\n",
    "\n",
    "image_size = [1280, 960]\n",
    "max_length = 1536\n",
    "\n",
    "\n",
    "config.encoder.image_size = image_size\n",
    "processor = DonutProcessor.from_pretrained(PROCESSORS_PATH+\"donut-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fe271bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = [\"<table_extraction>\", \"<table>\", \"<row>\", \"<cell>\", \"<row_and_col_header>\", \"<row_header>\", \"<col_header>\"]\n",
    "new_tokens += [\"<content_row_and_col_header>\", \"<content_row_header>\", \"<content_col_header>\", \"<content>\"]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            new_tokens.append(\"<span_type=0\" + str(i) + str(j) + str(k) + \">\")\n",
    "            new_tokens.append(\"<span_type=1\" + str(i) + str(j) + str(k) + \">\")\n",
    "\n",
    "\n",
    "processor.tokenizer.add_tokens(new_tokens, special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50455328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = [\"<cell>\", \"<row_and_col_header>\", \"<row_header>\", \"<col_header>\"]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            cell_types.append(\"<span_type=0\" + str(i) + str(j) + str(k) + \">\")\n",
    "            cell_types.append(\"<span_type=1\" + str(i) + str(j) + str(k) + \">\")\n",
    "\n",
    "\n",
    "cell_tokens = [processor.tokenizer.convert_tokens_to_ids([cell_type])[0] for cell_type in cell_types]\n",
    "row_tokens = [processor.tokenizer.convert_tokens_to_ids([row_type])[0] for row_type in ['<row>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7649821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<row>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(row_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38575e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the decoder: <class 'modeling_dimbart.DiMBartForCausalLM'> is overwritten by shared decoder config: DiMBartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"dim_max_position_embeddings\": [\n",
      "    512,\n",
      "    120,\n",
      "    120\n",
      "  ],\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"max_position_embeddings\": 1536,\n",
      "  \"model_type\": \"dimbart\",\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pos_counters\": [\n",
      "    [\n",
      "      57528,\n",
      "      57529,\n",
      "      57530,\n",
      "      57531,\n",
      "      57536,\n",
      "      57537,\n",
      "      57538,\n",
      "      57539,\n",
      "      57540,\n",
      "      57541,\n",
      "      57542,\n",
      "      57543,\n",
      "      57544,\n",
      "      57545,\n",
      "      57546,\n",
      "      57547,\n",
      "      57548,\n",
      "      57549,\n",
      "      57550,\n",
      "      57551\n",
      "    ],\n",
      "    [\n",
      "      57527\n",
      "    ]\n",
      "  ],\n",
      "  \"scale_embedding\": true,\n",
      "  \"transformers_version\": \"4.41.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 57525\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(57552, 1024)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TabeleiroModel.from_pretrained(\"naver-clova-ix/donut-base\",\n",
    "                                       from_donut=True,\n",
    "                                       decoder_extra_config={\"pos_counters\":[cell_tokens, row_tokens]},\n",
    "                                       donut_config = config,\n",
    "                                       ignore_mismatched_sizes=True)\n",
    "model.decoder.resize_token_embeddings(len(processor.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffc6e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderConfig {\n",
       "  \"_name_or_path\": \"naver-clova-ix/donut-base\",\n",
       "  \"architectures\": [\n",
       "    \"VisionEncoderDecoderModel\"\n",
       "  ],\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"add_final_layer_norm\": true,\n",
       "    \"architectures\": null,\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 4,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"dim_max_position_embeddings\": [\n",
       "      512,\n",
       "      120,\n",
       "      120\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 1536,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"dimbart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"pos_counters\": [\n",
       "      [\n",
       "        57528,\n",
       "        57529,\n",
       "        57530,\n",
       "        57531,\n",
       "        57536,\n",
       "        57537,\n",
       "        57538,\n",
       "        57539,\n",
       "        57540,\n",
       "        57541,\n",
       "        57542,\n",
       "        57543,\n",
       "        57544,\n",
       "        57545,\n",
       "        57546,\n",
       "        57547,\n",
       "        57548,\n",
       "        57549,\n",
       "        57550,\n",
       "        57551\n",
       "      ],\n",
       "      [\n",
       "        57527\n",
       "      ]\n",
       "    ],\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": true,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 57552\n",
       "  },\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": null,\n",
       "    \"attention_probs_dropout_prob\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      14,\n",
       "      2\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"drop_path_rate\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"embed_dim\": 128,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.0,\n",
       "    \"hidden_size\": 1024,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"image_size\": [\n",
       "      1280,\n",
       "      960\n",
       "    ],\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-05,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"min_length\": 0,\n",
       "    \"mlp_ratio\": 4.0,\n",
       "    \"model_type\": \"donut-swin\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_channels\": 3,\n",
       "    \"num_heads\": [\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32\n",
       "    ],\n",
       "    \"num_layers\": 4,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"patch_size\": 4,\n",
       "    \"path_norm\": true,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"qkv_bias\": true,\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_absolute_embeddings\": false,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"window_size\": 10\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"vision-encoder-decoder\",\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.41.0\"\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63430609",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.image_processor.size = image_size[::-1] # should be (width, height)\n",
    "#processor.image_processor.size = {'width': image_size[::-1][0], 'height': image_size[::-1][1]}\n",
    "processor.image_processor.do_align_long_axis = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c74cf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"msg.json\", 'w') as out:\n",
    "        json.dump({'outputs': []}, out, ensure_ascii=False, indent=4)\n",
    "\n",
    "def write_msg(msg):\n",
    "    with open(\"msg.json\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    with open(\"msg.json\", 'w') as out:\n",
    "        json_data['outputs'].append(msg)\n",
    "        json.dump(json_data, out, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07bba3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cel2token(cell):\n",
    "    if cell['span_type'][10:] != '0000':\n",
    "        sequence = \"<\" + cell['span_type'] + \">\"\n",
    "        if cell['content_holder']:\n",
    "            if cell['row_header'] and cell['col_header']:\n",
    "                sequence += \"<content_row_and_col_header>\"\n",
    "            elif cell['col_header']:\n",
    "                sequence += \"<content_col_header>\"\n",
    "            elif cell['row_header']:\n",
    "                sequence += \"<content_row_header>\"\n",
    "            else:\n",
    "                sequence += \"<content>\"\n",
    "            sequence += cell['content']\n",
    "    else:\n",
    "        sequence = \"\"\n",
    "        if cell['content_holder']:\n",
    "            if cell['row_header'] and cell['col_header']:\n",
    "                sequence += \"<row_and_col_header>\"\n",
    "            elif cell['col_header']:\n",
    "                sequence += \"<col_header>\"\n",
    "            elif cell['row_header']:\n",
    "                sequence += \"<row_header>\"\n",
    "            else:\n",
    "                sequence += \"<cell>\"\n",
    "            sequence += cell['content']\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def row2token(row):\n",
    "    sequence = \"<row>\"\n",
    "    for cell in row:\n",
    "        sequence += cel2token(cell)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "\n",
    "def table2token(table):\n",
    "    sequence = \"<table>\"\n",
    "    for row in table:\n",
    "        sequence += row2token(row)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "\n",
    "def json2token(json):\n",
    "    sequence = \"\"\n",
    "    if('tables' in json):\n",
    "        for table in json['tables']:\n",
    "            sequence += table2token(table)\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d32c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonutTableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        image_size,\n",
    "        max_length,\n",
    "        shuffle = True,\n",
    "        split = \"train\",\n",
    "        ignore_id = -100,\n",
    "        prompt_end_token = None,\n",
    "    ):            \n",
    "        self.annotations = annotations\n",
    "        \n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.annotations[idx]\n",
    "        \n",
    "        with open(ANN_PATH + file_name + \".json\", encoding=\"utf-8\") as f:\n",
    "            annotation = json.load(f)\n",
    "        \n",
    "        image = Image.open(IMAGE_PATH + file_name + IMG_FORMAT)\n",
    "        \n",
    "        \n",
    "        # inputs\n",
    "        pixel_values = processor(image.convert(\"RGB\"), random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        #pixel_values = processor(image.convert(\"RGB\"), return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "        \n",
    "        target_sequence = json2token(annotation)+\"</s>\"\n",
    "        \n",
    "        input_ids = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length= max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id\n",
    "        \n",
    "        \n",
    "        encoding = dict(pixel_values=pixel_values,\n",
    "                        labels=labels,\n",
    "                        target = target_sequence,\n",
    "                       filename = file_name)\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c2595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DonutTableDataset(json_list,\n",
    "                             max_length = max_length,\n",
    "                             image_size = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5c6d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29be2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointed = False\n",
    "if checkpointed:\n",
    "    model = TabeleiroModel.from_pretrained(\"../../pubtabnet/checkpoints/TML-5lre-5-checkpoint\")\n",
    "\n",
    "start_epoch = 0\n",
    "avg_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d7f93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids([\"<table_extraction>\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d475c75e3c6a4939b7b26d2777a7e1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss:  0.019431493759155274\n",
      "1000 Loss:  6.579685248613358\n",
      "2000 Loss:  5.570272281885147\n",
      "3000 Loss:  5.2339400794506075\n",
      "4000 Loss:  4.98133663058281\n",
      "5000 Loss:  4.7941161029338835\n",
      "6000 Loss:  4.606940300226212\n",
      "7000 Loss:  4.51146121096611\n",
      "8000 Loss:  4.369715010881424\n",
      "9000 Loss:  4.253800024271011\n",
      "10000 Loss:  4.0575041978359225\n",
      "11000 Loss:  3.9440036565065384\n",
      "12000 Loss:  3.7924867882728575\n",
      "13000 Loss:  3.7100372223854063\n",
      "14000 Loss:  3.573462166786194\n",
      "15000 Loss:  3.505331085562706\n",
      "16000 Loss:  3.4150975004434585\n",
      "17000 Loss:  3.348776025414467\n",
      "18000 Loss:  3.3226350647211076\n",
      "20000 Loss:  3.20128557908535\n",
      "21000 Loss:  3.1664947514533996\n",
      "22000 Loss:  3.0807485001087187\n",
      "23000 Loss:  3.0895066096782684\n",
      "24000 Loss:  2.986276115298271\n",
      "25000 Loss:  2.9030697116851805\n",
      "26000 Loss:  2.815761838555336\n",
      "27000 Loss:  2.719779305458069\n",
      "28000 Loss:  2.5916754891872404\n",
      "29000 Loss:  2.4664889006614685\n",
      "30000 Loss:  2.304035267114639\n",
      "31000 Loss:  2.149333081305027\n",
      "32000 Loss:  1.9695193829536437\n",
      "33000 Loss:  1.8022592048048973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41000 Loss:  0.7964887694567442\n",
      "42000 Loss:  0.7603453059345484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 Loss:  0.5066187719739974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159000 Loss:  0.13310842681583018\n",
      "160000 Loss:  0.1350598122002557\n",
      "161000 Loss:  0.13373282116907648\n",
      "162000 Loss:  0.12928155067376793\n",
      "163000 Loss:  0.1297168008373119\n",
      "164000 Loss:  0.1354494934277609\n",
      "165000 Loss:  0.13802727720374242\n",
      "166000 Loss:  0.12858556186419445\n",
      "167000 Loss:  0.12831468836171553\n",
      "168000 Loss:  0.133697716641007\n",
      "169000 Loss:  0.12705815687356517\n",
      "170000 Loss:  0.12675119307497515\n",
      "171000 Loss:  0.12964414239465258\n",
      "172000 Loss:  0.12829330206220038\n",
      "173000 Loss:  0.12719114545965568\n",
      "174000 Loss:  0.12373946292279288\n",
      "175000 Loss:  0.12237162798130885\n",
      "176000 Loss:  0.12165181694645434\n",
      "177000 Loss:  0.13027850967319682\n",
      "178000 Loss:  0.12762301125889644\n",
      "179000 Loss:  0.11849448135634884\n",
      "180000 Loss:  0.1247072758488357\n",
      "181000 Loss:  0.1360535234727431\n",
      "182000 Loss:  0.1371152920324821\n",
      "183000 Loss:  0.12800049334391952\n",
      "184000 Loss:  0.1253107860372402\n",
      "185000 Loss:  0.12089928129641339\n",
      "186000 Loss:  0.11178982891654596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194000 Loss:  0.1121950489655137\n",
      "195000 Loss:  0.12555741201061754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202000 Loss:  0.11987798615451903\n",
      "203000 Loss:  0.10460120011097751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211000 Loss:  0.11669942296436056\n",
      "212000 Loss:  0.1068989670369774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220000 Loss:  0.10602523202262819\n",
      "221000 Loss:  0.11019037523376755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229000 Loss:  0.09993554190313443\n",
      "230000 Loss:  0.11565741922799498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238000 Loss:  0.10080951290973462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247000 Loss:  0.10069777534715832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch's mean loss:  0.6707824975716244\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e838abd24143e9afbda2080cb017e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss:  3.0817363411188125e-05\n",
      "1000 Loss:  0.09620636752736755\n",
      "2000 Loss:  0.08878369514364749\n",
      "3000 Loss:  0.10037023006635717\n",
      "4000 Loss:  0.09878374094236642\n",
      "5000 Loss:  0.08831019568629563\n",
      "6000 Loss:  0.08873368344816845\n",
      "7000 Loss:  0.09038263808912597\n",
      "8000 Loss:  0.09261249706172384\n",
      "9000 Loss:  0.08964814999257215\n",
      "10000 Loss:  0.09221918969089166\n",
      "11000 Loss:  0.09058927550679073\n",
      "12000 Loss:  0.09795042866724543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ae009709900>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jao/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jao/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ae009709900>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jao/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jao/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 Loss:  0.09136406291672029\n",
      "14000 Loss:  0.09644539151107892\n",
      "15000 Loss:  0.09122672167723067\n",
      "16000 Loss:  0.09054992309794761\n",
      "17000 Loss:  0.09580639433898613\n",
      "18000 Loss:  0.08652131885546259\n",
      "19000 Loss:  0.08949715572712012\n",
      "20000 Loss:  0.09204902194230817\n",
      "21000 Loss:  0.09261350147426128\n",
      "22000 Loss:  0.09093757746298797\n",
      "23000 Loss:  0.09568822903325781\n",
      "24000 Loss:  0.08866828897316009\n",
      "25000 Loss:  0.09185098999459297\n",
      "26000 Loss:  0.0897846066148486\n",
      "27000 Loss:  0.09033431838813703\n",
      "28000 Loss:  0.09406241922010668\n",
      "29000 Loss:  0.09349229171103798\n",
      "30000 Loss:  0.08698566903639585\n",
      "31000 Loss:  0.09054351398767903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000 Loss:  0.08742814011615702\n",
      "33000 Loss:  0.08973938377085142\n",
      "34000 Loss:  0.0892279680124484\n",
      "35000 Loss:  0.10130262071359902\n",
      "36000 Loss:  0.08929941336449701\n",
      "37000 Loss:  0.08955208923842292\n",
      "38000 Loss:  0.08368041290226393\n",
      "39000 Loss:  0.09573100243927911\n",
      "40000 Loss:  0.09206503663840704\n",
      "41000 Loss:  0.08958506098482757\n",
      "42000 Loss:  0.09263629957434023\n",
      "43000 Loss:  0.09351787567837164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44000 Loss:  0.081754000331508\n",
      "45000 Loss:  0.08918775191996246\n",
      "46000 Loss:  0.09570151437167078\n",
      "47000 Loss:  0.08888829842349515\n",
      "48000 Loss:  0.08998926596390083\n",
      "49000 Loss:  0.09450552242109551\n",
      "50000 Loss:  0.09192389869631734\n",
      "51000 Loss:  0.0875583226904273\n",
      "52000 Loss:  0.09080112065048888\n",
      "53000 Loss:  0.0936175594984088\n",
      "54000 Loss:  0.0905509135684697\n",
      "55000 Loss:  0.08722285960172303\n",
      "56000 Loss:  0.09153266572509892\n",
      "57000 Loss:  0.08783090206515044\n",
      "58000 Loss:  0.08461184310051613\n",
      "59000 Loss:  0.09155658865359147\n",
      "60000 Loss:  0.08666705016186461\n",
      "61000 Loss:  0.09301575409597718\n",
      "62000 Loss:  0.08724790156818926\n",
      "63000 Loss:  0.08603669470199383\n",
      "65000 Loss:  0.08271063947700895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74000 Loss:  0.0903660613016691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83000 Loss:  0.08234748573740944\n",
      "84000 Loss:  0.08836262114695273\n",
      "85000 Loss:  0.07854300408880226\n",
      "86000 Loss:  0.09103077826381195\n",
      "87000 Loss:  0.084492337531643\n",
      "88000 Loss:  0.08815159448096528\n",
      "89000 Loss:  0.08285651571094059\n",
      "90000 Loss:  0.08768805241188966\n",
      "91000 Loss:  0.09049247764749452\n",
      "92000 Loss:  0.08226871493156068\n",
      "93000 Loss:  0.08380051378801\n",
      "94000 Loss:  0.08476647816435434\n",
      "95000 Loss:  0.08603307229687926\n",
      "96000 Loss:  0.07757736642390956\n",
      "97000 Loss:  0.08358916757884435\n",
      "98000 Loss:  0.09153812893945724\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model.to(device) \n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=8e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=len(train_dataloader)//27, gamma=(0.125)**(1/27))\n",
    "\n",
    "if checkpointed:\n",
    "    optimizer.load_state_dict(torch.load(\"../../pubtabnet/checkpoints/optim-checkpoint\"))\n",
    "\n",
    "num_steps = 0   \n",
    "\n",
    "for epoch in range(start_epoch, 2):\n",
    "    \n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    mean_loss = 0\n",
    "    mean_smpl_loss = 0 \n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "            \n",
    "        batch = {k: v.to(device) if k not in [\"target\", \"filename\"] else v for k, v in batch.items()}\n",
    "        \n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        \n",
    "        \n",
    "        loss = outputs.loss\n",
    "        mean_loss += loss.item()   \n",
    "        mean_smpl_loss += loss.item()\n",
    "        \n",
    "        loss /= 4\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i+1)%4 == 0 or i+1 == len(train_dataloader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            num_steps += 1\n",
    "            if num_steps%10000 == 0 :\n",
    "                model.save_pretrained(\"../../pubtabnet/modelos/by_step/model-3D-STEP_\"+str(num_steps))\n",
    "        \n",
    "        if  scheduler.get_last_lr()[0] > 1e-5:\n",
    "            scheduler.step() \n",
    "                \n",
    "        if i % avg_size == 0:\n",
    "            print(str(i) + \" Loss: \", mean_smpl_loss/avg_size)\n",
    "            write_msg(\"batch \" + str(i) +\" loss: \"+ str(mean_smpl_loss/avg_size))\n",
    "            mean_smpl_loss = 0 \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    model.save_pretrained(\"../../pubtabnet/checkpoints/TML-5lre-5-8kproc-checkpoint-epoch\"+str(epoch))\n",
    "    print(\"Epoch's mean loss: \", mean_loss/len(train_dataloader))\n",
    "    \n",
    "    write_msg(\"Epoch checkpointed: \" + str(epoch+1) +\" \\n\"+\n",
    "              \"Epoch's mean Loss: \" + str(mean_loss/len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.decode([57525, 57526, 57527])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../../pubtabnet/modelos/model-3D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041efb6d",
   "metadata": {},
   "source": [
    "#### processor.save_pretrained(\"../../pubtabnet/processors/processor-GTML-8kproc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6cd87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2375e00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
