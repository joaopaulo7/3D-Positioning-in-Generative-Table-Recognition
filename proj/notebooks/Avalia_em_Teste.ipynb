{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b30e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jao/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from transformers import DonutProcessor\n",
    "from modeling_tabeleiro import TabeleiroModel\n",
    "from processing_tabeleiro import TabeleiroProcessor\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IMG_PATH = \"../../aux/data/imgs/final_eval/\"\n",
    "\n",
    "filelist = os.listdir(IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe91e4b-2fd9-42cc-bf3d-516cf4295b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8621fa63b29c02efea427bdb210e3d896a8ba07299052095ee6eb94d2218aca5.png',\n",
       " 'cb8ce80fc6149d3c9af03f52f0bb3075778b8a28e18324e6bfee084838b8cb02.png',\n",
       " 'f3b0b3c68db9f71dbc32f53f26a79d839410bb1260a75a685d843d45e45e1781.png',\n",
       " '63eff125664ac9e982bbda705cde8c6ce1cdbd9a799e5fca97fe917be81d84dd.png',\n",
       " '69b44706b64364cca8e5045717597e1f68c23e1fc283c89bec879bfa2acec7c2.png',\n",
       " '11cd20efc60a947c217c9916e28dd05102c2ba05cf78b545e49b1bf117b347c6.png',\n",
       " 'ef4c7af62ccd6d6834e04a4ac6395f19340e146e6c97a834dc00de0bb0e8aec7.png',\n",
       " 'cb375b39cfa1fa47466a5396acfb0f4fa02fe136b0059c820cb7ce9ef0a1263a.png',\n",
       " 'a1e8f4e48b1d6f7fa511e41f06e210a0de145bc2771dd4da243f9f3af2138794.png',\n",
       " '4cf7fe0232d3be583721f6bf38b3ef4b1db3479a431c367cfa4a1b10b5511c83.png']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702163df-f3f8-49cf-877f-900d321fece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(IMG_PATH + filelist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73627428-c51d-4132-86da-cb7ab2e4ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=486x113 at 0x7229A04240A0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091dc69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type dimbart to instantiate a model of type mbart. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model = TabeleiroModel.from_pretrained(\"../../aux/models/model_3D-STEP_60000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3de26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = TabeleiroProcessor.from_pretrained(\"../../aux/processors/donut-base\")\n",
    "processor.image_processor.size = model.encoder.config.image_size[::-1] # should be (width, height)\n",
    "processor.image_processor.do_align_long_axis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cbd67aa-733f-435d-b835-bfb0b6f3890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabeleiroProcessor:\n",
       "- image_processor: DonutImageProcessor {\n",
       "  \"_valid_processor_keys\": [\n",
       "    \"images\",\n",
       "    \"do_resize\",\n",
       "    \"size\",\n",
       "    \"resample\",\n",
       "    \"do_thumbnail\",\n",
       "    \"do_align_long_axis\",\n",
       "    \"do_pad\",\n",
       "    \"random_padding\",\n",
       "    \"do_rescale\",\n",
       "    \"rescale_factor\",\n",
       "    \"do_normalize\",\n",
       "    \"image_mean\",\n",
       "    \"image_std\",\n",
       "    \"return_tensors\",\n",
       "    \"data_format\",\n",
       "    \"input_data_format\"\n",
       "  ],\n",
       "  \"do_align_long_axis\": false,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_pad\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"do_thumbnail\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"DonutImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"processor_class\": \"DonutProcessor\",\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": [\n",
       "    1200,\n",
       "    900\n",
       "  ]\n",
       "}\n",
       "\n",
       "- tokenizer: XLMRobertaTokenizerFast(name_or_path='../../aux/processors/donut-base', vocab_size=57522, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<s_iitcdip>', '<s_synthdog>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t57521: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "\t57522: AddedToken(\"<sep/>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57523: AddedToken(\"<s_iitcdip>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t57524: AddedToken(\"<s_synthdog>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t57525: AddedToken(\"<table_extraction>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57526: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57527: AddedToken(\"<row>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57528: AddedToken(\"<content_row_and_col_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57529: AddedToken(\"<content_row_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57530: AddedToken(\"<content_col_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57531: AddedToken(\"<content>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57532: AddedToken(\"<cell>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57533: AddedToken(\"<col_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57534: AddedToken(\"<row_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57535: AddedToken(\"<row_and_col_header>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57536: AddedToken(\"<span_type=0000>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57537: AddedToken(\"<span_type=1000>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57538: AddedToken(\"<span_type=0001>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57539: AddedToken(\"<span_type=1001>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57540: AddedToken(\"<span_type=0010>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57541: AddedToken(\"<span_type=1010>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57542: AddedToken(\"<span_type=0011>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57543: AddedToken(\"<span_type=1011>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57544: AddedToken(\"<span_type=0100>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57545: AddedToken(\"<span_type=1100>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57546: AddedToken(\"<span_type=0101>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57547: AddedToken(\"<span_type=1101>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57548: AddedToken(\"<span_type=0110>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57549: AddedToken(\"<span_type=1110>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57550: AddedToken(\"<span_type=0111>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t57551: AddedToken(\"<span_type=1111>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"TabeleiroProcessor\"\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "542d3e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderConfig {\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"../../aux/models/model_3D-STEP_60000/dimbart_decoder\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"add_final_layer_norm\": true,\n",
       "    \"architectures\": [\n",
       "      \"DiMBartForCausalLM\"\n",
       "    ],\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 4,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"dim_max_position_embeddings\": [\n",
       "      514,\n",
       "      120,\n",
       "      120\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 1536,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"mbart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"pos_counters\": [\n",
       "      [\n",
       "        57532,\n",
       "        57535,\n",
       "        57534,\n",
       "        57533,\n",
       "        57536,\n",
       "        57537,\n",
       "        57538,\n",
       "        57539,\n",
       "        57540,\n",
       "        57541,\n",
       "        57542,\n",
       "        57543,\n",
       "        57544,\n",
       "        57545,\n",
       "        57546,\n",
       "        57547,\n",
       "        57548,\n",
       "        57549,\n",
       "        57550,\n",
       "        57551\n",
       "      ],\n",
       "      [\n",
       "        57527\n",
       "      ]\n",
       "    ],\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": true,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": \"float32\",\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 57552\n",
       "  },\n",
       "  \"decoder_start_token_id\": 57525,\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"../../aux/models/model_3D-STEP_60000/donut_encoder\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": [\n",
       "      \"DonutSwinModel\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      14,\n",
       "      2\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"drop_path_rate\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"embed_dim\": 128,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.0,\n",
       "    \"hidden_size\": 1024,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"image_size\": [\n",
       "      900,\n",
       "      1200\n",
       "    ],\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-05,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"min_length\": 0,\n",
       "    \"mlp_ratio\": 4.0,\n",
       "    \"model_type\": \"donut-swin\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_channels\": 3,\n",
       "    \"num_heads\": [\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32\n",
       "    ],\n",
       "    \"num_layers\": 4,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"patch_size\": 4,\n",
       "    \"path_norm\": true,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"qkv_bias\": true,\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": \"float32\",\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_absolute_embeddings\": false,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"window_size\": 10\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"vision-encoder-decoder\",\n",
       "  \"pad_token_id\": 1,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.41.0\"\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids([\"<table_extraction>\"])[0]\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c889d88-10bb-45a4-871e-c065e610051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<row>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(57527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d483ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonutTableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        max_length,\n",
    "        ignore_id = -100,\n",
    "        prompt_end_token = None,\n",
    "    ):            \n",
    "        self.annotations_files = list(annotations.keys())\n",
    "        self.annotations = annotations\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.ignore_id = ignore_id        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.annotations_files[idx]\n",
    "        \n",
    "        gt = self.annotations[file_name]['html']\n",
    "        \n",
    "        image = Image.open(IMG_PATH + file_name)\n",
    "        \n",
    "        \n",
    "        # inputs\n",
    "        pixel_values = processor(image.convert(\"RGB\"), random_padding=False, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "        \n",
    "        encoding = dict(file_name = file_name,\n",
    "                        pixel_values=pixel_values,\n",
    "                        gt = gt)\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b060b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../aux/data/anns/test/final_eval.json') as fp:\n",
    "    annotations = json.load(fp)\n",
    "\n",
    "test_set = DonutTableDataset(annotations, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "545ac3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(processor.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "718d2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../../aux/PubTabNet/src/')\n",
    "from metric import TEDS\n",
    "\n",
    "teds = TEDS(n_jobs=4, structure_only = True, ignore_nodes = [\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07f281e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7339d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/9064 [00:00<1:32:43,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e87bba5267499998e22dc7e6b826adea9c0d3ff1a843f8ea24b55db5dea6fd86.png\n",
      "<s><table_extraction><table><row><col_header> <b>Gene</b><col_header> <b>Primer sequence</b><row><cell> Collagen X<cell> Formal primer 5′-GCCCCTTCTGCTAGTGCTAGCTAGCT<row><cell> Reverse primer 5′ Reverse primer 5′</s></s></s>\n",
      "0.0 -- 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 2/9064 [00:09<13:23:17,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a52c0f276b273a14ad1a6b8424887106601733310cc62e7d326ad01ecfac1bd2.png\n",
      "<s><table_extraction><table><row><col_header> <b>Studies</b><col_header> <b>Outcomes reported</b><col_header> <b>Types of participants<row><cell> Cavallasca 2008 [16]<cell> Stillbirth<cell> Stillbirth<cell> SLE versus<row><cell> SLE versus<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle<cell> Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle<cell> Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle<cell> Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle<cell> Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle<cell> Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle Sle S</s></s></s>\n",
      "0.0 -- 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 3/9064 [00:18<17:27:51,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f2e33bdb03a47b2dc32664508679f2b2a7b313f5e2d096cbeb2be89614d7ceb6.png\n",
      "<s><table_extraction><table><row><col_header><col_header> <b>Total</b><col_header> <b>Fixed-dose group</b><col_header><col_header> <b>Fixed-dose group</b><row><cell> January**<cell> 22.7<cell> 24.4<cell> 22.7<cell> 22.7<cell> 22.7<cell> 22.7<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 22.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8<cell> 22.7 ± 2.5<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 23.6 ± 1.0<cell> 22.7 ± 1.0<cell> 22.7 ± 1.0<cell> 23.6 ± 1.0<cell> 23.8<cell> 23.6 ± 1.0<cell> 22.9 ± 1.0<cell> 22.9 ± 1.0<cell> 22.9 ± 1.0<cell> 22.9 ± 1.0<cell> 23.8<cell> 23.8<cell> 23.8<cell> 23.8 ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> 23.4 ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.8 ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> ± 1.0<cell> ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> 23.4 ± 1.0<cell> ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.4 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> ± 1.0<cell> 23.3 ± 1.0<cell> ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell> 23.3 ± 1.0<cell></s></s></s>\n",
      "0.0 -- 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 4/9064 [00:26<19:10:19,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772b165aa6f4730bcf96b4ea4d16d34bef666bf22253825c1c351c25588991b0.png\n",
      "<s><table_extraction><table><row><col_header><col_header> <b>No. herds</b><col_header> <b>End of one year study period</b><col_header> <b>Herd</b><col_header> <b>Herd</b> of year</b><col_header> <sup>Herd</b> of one year</b><row><cell> Herd</b><cell> Herd</b><row><cell><cell><cell><cell><cell><cell><cell><cell><cell><cell><cell><cell><cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45<cell> 45d</b><cell> 45d</b><cell> 45d</b><cell> 45d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b>d</b></s></s></s>\n",
      "0.1333333333333333 -- 0.033333333333333326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 4/9064 [00:31<19:38:37,  7.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m gt \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m <\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# autoregressively generate sequence\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munk_token_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((outputs\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mto(device)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(filename)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1773\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1765\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1766\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1767\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1768\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1769\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1770\u001b[0m     )\n\u001b[1;32m   1772\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1773\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1787\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1788\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1795\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2632\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 2632\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2640\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py:615\u001b[0m, in \u001b[0;36mVisionEncoderDecoderModel.forward\u001b[0;34m(self, pixel_values, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m     decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m    611\u001b[0m         labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py:2080\u001b[0m, in \u001b[0;36mMBartForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2077\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 2080\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2095\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2097\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UFLA/projeto_IC/table_extraction/proj/notebooks/../src/modeling_dimbart.py:335\u001b[0m, in \u001b[0;36mDiMBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    322\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    323\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    324\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m         use_cache,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py:676\u001b[0m, in \u001b[0;36mMBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    675\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    685\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py:274\u001b[0m, in \u001b[0;36mMBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    270\u001b[0m     attn_weights_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    272\u001b[0m attn_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m--> 274\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "out_dics = {}\n",
    "sum_score = 0\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "decoder_input_ids = processor.tokenizer(\"<table_extraction>\", add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "    \n",
    "    pixel_values = batch[\"pixel_values\"].to(device)\n",
    "    filename = batch[\"file_name\"][0]\n",
    "    gt = batch['gt'][0].replace(\"> \", \">\").replace(\" <\", \"<\")\n",
    "    \n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "        pixel_values,\n",
    "        decoder_input_ids=decoder_input_ids.to(device),\n",
    "        max_length= 1600,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams= 3,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "        )\n",
    "    \n",
    "    seq = torch.cat((outputs.sequences[0], torch.Tensor([2, 2]).int().to(device)), 0)\n",
    "    print(filename)\n",
    "    print(processor.decode(seq))\n",
    "    table = processor.token2ann(seq, 1)\n",
    "    \n",
    "    table_html = \"<html><body><table>\" + processor.table2html(table['tables'][0]).replace(\"> \", \">\").replace(\" <\", \"<\") + \"</table></body></html>\"\n",
    "    \n",
    "    \n",
    "    score = teds.evaluate(table_html, gt)\n",
    "    sum_score += score\n",
    "    \n",
    "    print(score,\"--\",sum_score/(i+1))\n",
    "    \n",
    "    out_dics[filename] = table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dic = out_dics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dics = cp_dic.copy()\n",
    "for filename in out_dics:\n",
    "    out_dics[filename] = \"<html><body><table>\" + out_dics[filename] + \"</table></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../pubtabnet/TML_pred_dic-EPOCH1.json\", 'w') as out:\n",
    "    json.dump(out_dics, out, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d62afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat((outputs.sequences[0], torch.tensor([processor.tokenizer.eos_token_id]).to(device)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa60e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../pubtabnet/final_eval.json\", encoding=\"utf-8\") as f:\n",
    "    gts = json.load(f)\n",
    "\n",
    "for gt in gts:\n",
    "    if(gt == \"663f4502ef940b47563185fb6dd16307b43b895fdb4fe1bbe8e514e6ad2bf6f2.png\"):\n",
    "        print(gts[gt]['html'].replace(\"<b>\", \"\").replace(\"</b>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839df77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
