{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b30e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers import VisionEncoderDecoderConfig\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IMG_PATH = \"../../pubtabnet/imgs/final_eval/\"\n",
    "IMG_FORMAT = \".png\"\n",
    "\n",
    "with open('../../pubtabnet/final_eval.json') as fp:\n",
    "    annotations = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091dc69b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at ../../pubtabnet/modelos/HTML-lre-5-epoch3 and are newly initialized: ['decoder.model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"../../pubtabnet/modelos/HTML-lre-5-epoch3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c1bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderConfig {\n",
       "  \"_name_or_path\": \"../../pubtabnet/modelos/HTML-lre-5-epoch3\",\n",
       "  \"architectures\": [\n",
       "    \"VisionEncoderDecoderModel\"\n",
       "  ],\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"add_final_layer_norm\": true,\n",
       "    \"architectures\": null,\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": 0.0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 1024,\n",
       "    \"decoder_attention_heads\": 16,\n",
       "    \"decoder_ffn_dim\": 4096,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 4,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 16,\n",
       "    \"encoder_ffn_dim\": 4096,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": 2,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 4096,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"mbart\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": true,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 57563\n",
       "  },\n",
       "  \"decoder_start_token_id\": 57525,\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": null,\n",
       "    \"attention_probs_dropout_prob\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": null,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      14,\n",
       "      2\n",
       "    ],\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"drop_path_rate\": 0.1,\n",
       "    \"early_stopping\": false,\n",
       "    \"embed_dim\": 128,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": null,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.0,\n",
       "    \"hidden_size\": 1024,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"image_size\": [\n",
       "      750,\n",
       "      750\n",
       "    ],\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-05,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"min_length\": 0,\n",
       "    \"mlp_ratio\": 4.0,\n",
       "    \"model_type\": \"donut-swin\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_channels\": 3,\n",
       "    \"num_heads\": [\n",
       "      4,\n",
       "      8,\n",
       "      16,\n",
       "      32\n",
       "    ],\n",
       "    \"num_layers\": 4,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"patch_size\": 4,\n",
       "    \"path_norm\": true,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"qkv_bias\": true,\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_absolute_embeddings\": false,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"window_size\": 10\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"vision-encoder-decoder\",\n",
       "  \"pad_token_id\": 1,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.35.0\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b29051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,  max_len: int, d_model: int, dropout: float = 0.05):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.offset = 2\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.pos_enc = pe.squeeze(1)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):\n",
    "        \"\"\"`input_ids' shape is expected to be [bsz x seqlen].\"\"\"\n",
    "\n",
    "        bsz, seq_len = input_ids.shape[:2]\n",
    "        \n",
    "        pos_start = past_key_values_length\n",
    "        pos_end = past_key_values_length+seq_len\n",
    "        \n",
    "        positions = self.pos_enc[pos_start:pos_end].expand(bsz, -1, -1)\n",
    "        \n",
    "        return self.dropout(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c49ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decoder.model.decoder.embed_positions = PositionalEncoding(4098, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3de26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 19:42:25.369206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-07 19:42:25.369234: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-07 19:42:25.369252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-07 19:42:25.921648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = DonutProcessor.from_pretrained(\"../../pubtabnet/Donut_PubTables_HTML_Processor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfadbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): DonutSwinModel(\n",
       "    (embeddings): DonutSwinEmbeddings(\n",
       "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): DonutSwinEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DonutSwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x DonutSwinLayer(\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): DonutSwinAttention(\n",
       "                (self): DonutSwinSelfAttention(\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): DonutSwinSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): DonutSwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): DonutSwinIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DonutSwinOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): DonutSwinPatchMerging(\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): DonutSwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x DonutSwinLayer(\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): DonutSwinAttention(\n",
       "                (self): DonutSwinSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): DonutSwinSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): DonutSwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): DonutSwinIntermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DonutSwinOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): DonutSwinPatchMerging(\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): DonutSwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-13): 14 x DonutSwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): DonutSwinAttention(\n",
       "                (self): DonutSwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): DonutSwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): DonutSwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): DonutSwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DonutSwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): DonutSwinPatchMerging(\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): DonutSwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x DonutSwinLayer(\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): DonutSwinAttention(\n",
       "                (self): DonutSwinSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): DonutSwinSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): DonutSwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): DonutSwinIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DonutSwinOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (decoder): MBartForCausalLM(\n",
       "    (model): MBartDecoderWrapper(\n",
       "      (decoder): MBartDecoder(\n",
       "        (embed_tokens): Embedding(57563, 1024, padding_idx=1)\n",
       "        (embed_positions): PositionalEncoding(\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x MBartDecoderLayer(\n",
       "            (self_attn): MBartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MBartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=57563, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d483ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DonutTableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        max_length,\n",
    "        ignore_id = -100,\n",
    "        prompt_end_token = None,\n",
    "    ):            \n",
    "        self.annotations_files = list(annotations.keys())\n",
    "        self.annotations = annotations\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.ignore_id = ignore_id        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.annotations_files[idx]\n",
    "        \n",
    "        gt = self.annotations[file_name]['html']\n",
    "        \n",
    "        image = Image.open(IMG_PATH + file_name)\n",
    "        \n",
    "        \n",
    "        # inputs\n",
    "        pixel_values = processor(image.convert(\"RGB\"), random_padding=False, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "        \n",
    "        encoding = dict(file_name = file_name,\n",
    "                        pixel_values=pixel_values,\n",
    "                        gt = gt)\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b060b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = DonutTableDataset(annotations, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f281e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "sys.path.insert(1, '../../pubtabnet/PubTabNet/src/')\n",
    "from metric import TEDS\n",
    "\n",
    "teds = TEDS(n_jobs=4, structure_only = False)\n",
    "\n",
    "train_dataloader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9854bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 57555, 57556, 57561, 57562, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer(\"<i></i><sub></sub>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7339d7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5522bf2fc3364e4f9986646c47eec08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9518190572487842 0.9518190572487842 336\n",
      "0.899509964469726 0.8472008716906676 542\n",
      "0.8992983296881706 0.8988750601250601 139\n",
      "0.8847507032161608 0.8411078238001315 783\n",
      "0.8457340090825592 0.6896672325481537 1107\n",
      "0.8537679832796635 0.8939378542651849 191\n",
      "0.8636118303188267 0.9226749125538053 211\n",
      "0.8651601652932276 0.8759985101140336 661\n",
      "0.861969812197048 0.8364469874276113 205\n",
      "0.8519314802007889 0.7615864922344565 412\n",
      "0.8521136507758108 0.8539353565260301 506\n",
      "0.8544580893428472 0.8802469135802469 170\n",
      "0.8541792011148363 0.8508325423787048 100\n",
      "0.8575498609718862 0.9013684391135371 389\n",
      "0.8574771099183119 0.8564585951682726 222\n",
      "0.858627163455995 0.8758779665212414 77\n",
      "0.8593171754821071 0.870357367899901 181\n",
      "0.8634195246422869 0.9331594603653427 164\n",
      "0.8624596702991599 0.8451822921228778 437\n",
      "0.8586690568050681 0.7866474004173236 1590\n",
      "0.8573673556873664 0.8313333333333334 572\n",
      "0.8563270085112612 0.8344797178130512 810\n",
      "0.8562129792976877 0.8537043365990734 719\n",
      "0.8558473112728895 0.8474369467025284 479\n",
      "0.8584304906390458 0.9204267954267954 276\n",
      "0.8594122290589782 0.8839556895572898 829\n",
      "0.8611754133444302 0.9070182047661832 223\n",
      "0.8614888481637807 0.8699515882862449 474\n",
      "0.8616491715146734 0.8661382253396664 230\n",
      "0.8617400385313462 0.8643751820148589 1318\n",
      "0.8600901433121706 0.8105932867369037 1098\n",
      "0.8602264459349942 0.8644518272425249 347\n",
      "0.8608476748743691 0.8807270009343644 410\n",
      "0.858500060868877 0.7810287986876403 1337\n",
      "0.8605946834973229 0.9318118528644844 262\n",
      "0.8596143893131267 0.8253040928662596 707\n",
      "0.8572318875736759 0.7714618249534451 460\n",
      "0.8564180647482911 0.8263066202090592 240\n",
      "0.8477674152331912 0.5190427336594003 1027\n",
      "0.8481152358193402 0.8616802386791456 1026\n",
      "0.8465967691317932 0.7858581016299138 301\n",
      "0.8439323257091538 0.7346901453809349 230\n",
      "0.8433314998099205 0.8180968120421246 561\n",
      "0.8444875541171771 0.894197889329216 476\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     19\u001b[0m     pixel_values,\n\u001b[1;32m     20\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     return_dict_in_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     30\u001b[0m table_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<html><body><table>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</table></body></html>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mteds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_html\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m sum_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(outputs\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5300\u001b[39m):\n",
      "File \u001b[0;32m~/testes/table_extraction/notebooks/../../pubtabnet/PubTabNet/src/metric.py:130\u001b[0m, in \u001b[0;36mTEDS.evaluate\u001b[0;34m(self, pred, true)\u001b[0m\n\u001b[1;32m    128\u001b[0m     tree_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_html_tree(pred)\n\u001b[1;32m    129\u001b[0m     tree_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_html_tree(true)\n\u001b[0;32m--> 130\u001b[0m     distance \u001b[38;5;241m=\u001b[39m \u001b[43mAPTED\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_edit_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(distance) \u001b[38;5;241m/\u001b[39m n_nodes)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/apted.py:106\u001b[0m, in \u001b[0;36mAPTED.compute_edit_distance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_opt_strategy_post_r()\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mted_init()\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/apted.py:377\u001b[0m, in \u001b[0;36mAPTED.gted\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    374\u001b[0m node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(path_id) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;241m<\u001b[39m it1\u001b[38;5;241m.\u001b[39mtree_size:  \u001b[38;5;66;03m# Apply on subtree 1\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_gted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Apply on subtree 2\u001b[39;00m\n\u001b[1;32m    380\u001b[0m node_id \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m it1\u001b[38;5;241m.\u001b[39mtree_size\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/apted.py:395\u001b[0m, in \u001b[0;36mAPTED.sub_gted\u001b[0;34m(self, data, it_f, it_s, tree_f, path_id, node_id, reverse)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m last:\n\u001b[1;32m    394\u001b[0m             data[it_f\u001b[38;5;241m.\u001b[39mnum] \u001b[38;5;241m=\u001b[39m child\n\u001b[0;32m--> 395\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m data[it_f\u001b[38;5;241m.\u001b[39mnum] \u001b[38;5;241m=\u001b[39m tree_f\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Pass to spfs a boolean that says says if the order of input\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# subtrees has been swapped compared to the order of the initial\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# input trees. Used for accessing delta array and deciding on the\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# edit operation. See [1, Section 3.4].\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/apted.py:377\u001b[0m, in \u001b[0;36mAPTED.gted\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    374\u001b[0m node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(path_id) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;241m<\u001b[39m it1\u001b[38;5;241m.\u001b[39mtree_size:  \u001b[38;5;66;03m# Apply on subtree 1\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_gted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Apply on subtree 2\u001b[39;00m\n\u001b[1;32m    380\u001b[0m node_id \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m it1\u001b[38;5;241m.\u001b[39mtree_size\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/apted.py:404\u001b[0m, in \u001b[0;36mAPTED.sub_gted\u001b[0;34m(self, data, it_f, it_s, tree_f, path_id, node_id, reverse)\u001b[0m\n\u001b[1;32m    398\u001b[0m data[it_f\u001b[38;5;241m.\u001b[39mnum] \u001b[38;5;241m=\u001b[39m tree_f\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Pass to spfs a boolean that says says if the order of input\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# subtrees has been swapped compared to the order of the initial\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# input trees. Used for accessing delta array and deciding on the\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# edit operation. See [1, Section 3.4].\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mit_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/single_path_functions.py:669\u001b[0m, in \u001b[0;36mSinglePathFunction.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 669\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLEFT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspf_l\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRIGHT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspf_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mINNER\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspf_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapted\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/single_path_functions.py:229\u001b[0m, in \u001b[0;36mSinglePathFunction.spf_r\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matb_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit2\u001b[38;5;241m.\u001b[39mpost_rtl_info\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswap\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspf_generic_side\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/single_path_functions.py:262\u001b[0m, in \u001b[0;36mSinglePathFunction.spf_generic_side\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Compute the distances between pairs of keyroot nodes. In the left-hand\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# input subtree only the root is the keyroot. Thus, we compute the distance\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# between the left-hand input subtree and all keyroot nodes in the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# right-hand input subtree.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(first_keyroot \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mtree_edit_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyroots\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforestdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forestdist[size1][size2]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/apted/single_path_functions.py:331\u001b[0m, in \u001b[0;36mSinglePathFunction.tree_edit_dist\u001b[0;34m(self, subtree1, subtree2, forestdist)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Calculate partial distance values for this subproblem.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo1_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo2_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m da \u001b[38;5;241m=\u001b[39m forestdist[i1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][j1] \u001b[38;5;241m+\u001b[39m delete(info1_node)\n\u001b[1;32m    333\u001b[0m db \u001b[38;5;241m=\u001b[39m forestdist[i1][j1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m insert(info2_node)\n",
      "File \u001b[0;32m~/testes/table_extraction/notebooks/../../pubtabnet/PubTabNet/src/metric.py:58\u001b[0m, in \u001b[0;36mCustomConfig.rename\u001b[0;34m(self, node1, node2)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node1\u001b[38;5;241m.\u001b[39mtag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node1\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m node2\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.\u001b[39m\n",
      "File \u001b[0;32m~/testes/table_extraction/notebooks/../../pubtabnet/PubTabNet/src/metric.py:50\u001b[0m, in \u001b[0;36mCustomConfig.normalized_distance\u001b[0;34m(self, *sequences)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalized_distance\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39msequences):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124;03m\"\"\"Get distance from 0 to 1\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevenshtein\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m*\u001b[39msequences)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/distance/_levenshtein.py:60\u001b[0m, in \u001b[0;36mlevenshtein\u001b[0;34m(seq1, seq2, max_dist, normalized)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, len2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     59\u001b[0m \told \u001b[38;5;241m=\u001b[39m column[y]\n\u001b[0;32m---> 60\u001b[0m \tcost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq2\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \tcolumn[y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(column[y] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, column[y \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, last \u001b[38;5;241m+\u001b[39m cost)\n\u001b[1;32m     62\u001b[0m \tlast \u001b[38;5;241m=\u001b[39m old\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "out_dics = {}\n",
    "sum_score = 0 \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "    \n",
    "    pixel_values = batch[\"pixel_values\"].to(device)\n",
    "    filename = batch[\"file_name\"][0]\n",
    "    gt = batch[\"gt\"][0].replace(\"> \", \">\")\n",
    "    \n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "        pixel_values,\n",
    "        early_stopping = True,\n",
    "        max_length= 4096,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams= 3,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True\n",
    "        )\n",
    "    \n",
    "    table_html = \"<html><body><table>\"+processor.tokenizer.decode(outputs.sequences[0][2:-1]).replace(\"> \", \">\")+ \"</table></body></html>\"\n",
    "    \n",
    "    score = teds.evaluate(table_html, gt)\n",
    "    sum_score += score\n",
    "    if(len(outputs.sequences[0]) > 5300):\n",
    "        print(table_html, \"\\n\\n\", gt)\n",
    "    print(sum_score/(i+1), score, len(outputs.sequences[0]))\n",
    "\n",
    "    \n",
    "    out_dics[filename] = table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../pubtabnet/HTML_pred_dic.json\", 'w') as out:\n",
    "    json.dump(out_dics, out, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d62afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat((outputs.sequences[0], torch.tensor([processor.tokenizer.eos_token_id]).to(device)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa60e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../pubtabnet/final_eval.json\", encoding=\"utf-8\") as f:\n",
    "    gts = json.load(f)\n",
    "\n",
    "for gt in gts:\n",
    "    if(gt == \"663f4502ef940b47563185fb6dd16307b43b895fdb4fe1bbe8e514e6ad2bf6f2.png\"):\n",
    "        print(gts[gt]['html'].replace(\"<b>\", \"\").replace(\"</b>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
